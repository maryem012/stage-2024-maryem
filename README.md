# stage-2024_cti
# Evaluation of Large Language Models in Cyber Threat Intelligence

### Project Overview
This project evaluates the capabilities of Large Language Models (LLMs) in performing Cyber Threat Intelligence (CTI) tasks. It includes assessments of models like LLaMA, Mistral, and Gemini AI using a specialized benchmark, **CTIBench**, which tests tasks such as multiple-choice question answering, root cause mapping, and vulnerability severity prediction.

#### Key Tasks Evaluated:
- **CTI-MCQ**: Cyber Threat Intelligence Multiple Choice Questions
- **CTI-RCM**: Cyber Threat Intelligence Root Cause Mapping
- **CTI-VSP**: Cyber Threat Intelligence Vulnerability Severity Prediction

The project benchmarks the performance of LLMs in these specific CTI tasks, identifies their strengths and limitations, and suggests areas for improvement.

### Table of Contents
- [Project Overview](#project-overview)
- [Installation](#installation)


### Installation

#### Prerequisites
Before setting up the project, make sure you have the following:

- Python 3.x
- Git
- Additional dependencies listed in `requirements.txt`

#### Steps to Install

1. **Clone the repository**:
   ```bash
   git clone https://github.com/maryem012/summerIntership_2024.git
